# 序列与编码器

## 机器翻译与数据集

语⾔模型是⾃然语⾔处理的关键，⽽机器翻译是语⾔模型最成功的基准测试。因为机器翻译正是将输⼊序列
转换成输出序列的序列转换模型（sequence transduction）的核⼼问题。

机器翻译指的是将序列从⼀种语⾔⾃动翻译成另⼀种语⾔。统计机器翻译涉及了翻译模型和语⾔模型等组成部分的统计分析，因此基于神经⽹络的⽅法通常被称为神经机器翻译，⽤于将两种翻译模型区分开来。

神经⽹络机器翻译⽅法，强调的是端到端的学习。机器翻译的数据集是由源语⾔和⽬标语⾔的⽂本序列对组成的。

* 机器翻译指的是将⽂本序列从⼀种语⾔⾃动翻译成另⼀种语⾔。
*  使⽤单词级词元化时的词表⼤⼩，将明显⼤于使⽤字符级词元化时的词表⼤⼩。为了缓解这⼀问题，我们可以将低频词元视为相同的未知词元。
* 通过截断和填充⽂本序列，可以保证所有的⽂本序列都具有相同的⻓度，以便以⼩批量的⽅式加载。  

## 编码器-解码器架构

机器翻译是序列转换模型的⼀个核⼼问题，其输⼊和输出都是⻓度可变的序列。为了处理这种类型的输⼊和输出，我们可以设计⼀个包含两个主要组件的架构：第⼀个组件是⼀个编码器（encoder）：它接受⼀个⻓度可变的序列作为输⼊，并将其转换为具有固定形状的编码状态。第⼆个组件是解码器（decoder）：它将固定形状的编码状态映射到⻓度可变的序列。这被称为编码器-解码器（encoder-decoder）架构。

![编码器与解码器](D:\DeepLearning2.0\DeepLearning2.0\循环神经网络\编码器与解码器.png)

• “编码器－解码器”架构可以将⻓度可变的序列作为输⼊和输出，因此适⽤于机器翻译等序列转换问题。
• 编码器将⻓度可变的序列作为输⼊，并将其转换为具有固定形状的编码状态。
• 解码器将具有固定形状的编码状态映射为⻓度可变的序列。  

## 序列到序列学习（seq2seq)

遵循编码器－解码器架构的设计原则，循环神经⽹络编码器使⽤⻓度可变的序列作为输⼊，将其转换为固定
形状的隐状态。换⾔之，输⼊序列的信息被编码到循环神经⽹络编码器的隐状态中。为了连续⽣成输出序列
的词元，独⽴的循环神经⽹络解码器是基于输⼊序列的编码信息和输出序列已经看⻅的或者⽣成的词元来预
测下⼀个词元。  

![使⽤循环神经⽹络编码器和循环神经⽹络解码器的序列到序列学习](D:\DeepLearning2.0\DeepLearning2.0\循环神经网络\使⽤循环神经⽹络编码器和循环神经⽹络解码器的序列到序列学习.png)

特定的“<eos>”表⽰序列结束词元。⼀旦输出序列⽣成此词元，模型就会停⽌预测。在循环神经⽹络解码器的初始化时间步，有两个特定的设计决定：⾸先，特定的“<bos>”表⽰序列开始词元，它是解码器的输⼊序列的第⼀个词元。其次，使⽤循环神经⽹络编码器最终的隐状态来初始化解码器的隐状态。如图所⽰，编码器最终的隐状态在每⼀个时间步都作为解码器的输⼊序列的⼀部分,可以允许标签成为原始的输出序列。

### 编码器

从技术上讲，编码器将长度可变的输入序列转换成形状固定的上下文变量$\mathbf{c}$，并且将输入序列的信息在该上下文变量中进行编码。可以使用循环神经网络来设计编码器。

考虑由一个序列组成的样本（批量大小是$1$）。假设输入序列是$x_1, \ldots, x_T$，其中$x_t$是输入文本序列中的第$t$个词元。在时间步$t$，循环神经网络将词元$x_t$的输入特征向量$\mathbf{x}_t$和$\mathbf{h} _{t-1}$（即上一时间步的隐状态）转换为$\mathbf{h}_t$（即当前步的隐状态）。使用一个函数$f$来描述循环神经网络的循环层所做的变换：

$$\mathbf{h}_t = f(\mathbf{x}_t, \mathbf{h}_{t-1}). $$

总之，编码器通过选定的函数$q$，将所有时间步的隐状态转换为上下文变量：

$$\mathbf{c} =  q(\mathbf{h}_1, \ldots, \mathbf{h}_T).$$

比如，当选择$q(\mathbf{h}_1, \ldots, \mathbf{h}_T) = \mathbf{h}_T$时，上下文变量仅仅是输入序列在最后时间步的隐状态$\mathbf{h}_T$。

到目前为止，我们使用的是一个单向循环神经网络来设计编码器，其中隐状态只依赖于输入子序列，这个子序列是由输入序列的开始位置到隐状态所在的时间步的位置（包括隐状态所在的时间步）组成。我们也可以使用双向循环神经网络构造编码器，其中隐状态依赖于两个输入子序列，两个子序列是由隐状态所在的时间步的位置之前的序列和之后的序列（包括隐状态所在的时间步），因此隐状态对整个序列的信息都进行了编码。

### 解码器

编码器输出的上下文变量$\mathbf{c}$对整个输入序列$x_1, \ldots, x_T$进行编码。来自训练数据集的输出序列$y_1, y_2, \ldots, y_{T'}$，对于每个时间步$t'$（与输入序列或编码器的时间步$t$不同），解码器输出$y_{t'}$的概率取决于先前的输出子序列$y_1, \ldots, y_{t'-1}$和上下文变量$\mathbf{c}$，即$P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \mathbf{c})$。

为了在序列上模型化这种条件概率，我们可以使用另一个循环神经网络作为解码器。在输出序列上的任意时间步$t^\prime$，循环神经网络将来自上一时间步的输出$y_{t^\prime-1}$和上下文变量$\mathbf{c}$作为其输入，然后在当前时间步将它们和上一隐状态
$\mathbf{s}_{t^\prime-1}$转换为隐状态$\mathbf{s}_{t^\prime}$。因此，可以使用函数$g$来表示解码器的隐藏层的变换：

$$\mathbf{s}_{t^\prime} = g(y_{t^\prime-1}, \mathbf{c}, \mathbf{s}_{t^\prime-1}).$$

在获得解码器的隐状态之后，我们可以使用输出层和$$softmax$$操作来计算在时间步$t^\prime$时输出$y_{t^\prime}$的条件概率分布
$P(y_{t^\prime} \mid y_1, \ldots, y_{t^\prime-1}, \mathbf{c})$。当实现解码器时，我们直接使用编码器最后一个时间步的隐状态来初始化解码器的隐状态。这就要求使用循环神经网络实现的编码器和解码器具有相同数量的层和隐藏单元。
为了进一步包含经过编码的输入序列的信息，上下文变量在所有的时间步与解码器的输入进行拼接。为了预测输出词元的概率分布，在循环神经网络解码器的最后一层使用全连接层来变换隐状态。

![循环神经⽹络编码器-解码器模型中的层](D:\DeepLearning2.0\DeepLearning2.0\循环神经网络\循环神经⽹络编码器-解码器模型中的层.png)

### 损失函数

在每个时间步，解码器预测了输出词元的概率分布。类似于语⾔模型，可以使⽤$$softmax$$来获得分布，并通过计算交叉熵损失函数来进⾏优化。特定的填充词元被添加到序列的末尾，因此不同⻓度的序列可以以相同形状的⼩批量加载。但是，我们应该将填充词元的预测排除在损失函数的计算之外。

为此，使⽤下⾯的sequence_mask函数通过零值化屏蔽不相关的项，以便后⾯任何不相关预测的计算都是与零的乘积，结果都等于零。例如，如果两个序列的有效⻓度（不包括填充词元）分别为1和2，则第⼀个序列的第⼀项和第⼆个序列的前两项之后的剩余项将被清除为零。  

```python
def sequence_mask(X, valid_len, value=0):
    """在序列中屏蔽不相关的项"""
    maxlen = X.size(1)
    mask = torch.arange((maxlen), dtype=torch.float32,
                        device=X.device)[None, :] < valid_len[:, None]
    X[~mask] = value
    return X
```

### 训练

特定的序列开始词元（“<bos>”）和原始的输出序列（不包括序列结束词元“<eos>”）拼接在⼀起作为解码器的输⼊。这被称为强制教学（teacher forcing），因为原始的输出序列（词元的标签）被送⼊解码器。或者，将来⾃上⼀个时间步的预测得到的词元作为解码器的当前输⼊。  

### 预测

为了采⽤⼀个接着⼀个词元的⽅式预测输出序列，每个解码器当前时间步的输⼊都将来⾃于前⼀时间步的预测词元。与训练类似，序列开始词元（“<bos>”）在初始时间步被输⼊到解码器中。该预测过程如 图9.7.3所⽰，当输出序列的预测遇到序列结束词元（“<eos>”）时，预测就结束了 。

![使⽤循环神经⽹络编码器-解码器逐词元地预测输出序列](D:\DeepLearning2.0\DeepLearning2.0\循环神经网络\使⽤循环神经⽹络编码器-解码器逐词元地预测输出序列.png)



### 预测序列的评估

我们可以通过与真实的标签序列进行比较来评估预测序列。BLEU（bilingual evaluation understudy）最先是用于评估机器翻译的结果，但现在它已经被广泛用于测量许多应用的输出序列的质量。原则上说，对于预测序列中的任意$n$元语法（n-grams），BLEU的评估都是这个$n$元语法是否出现在标签序列中。

将BLEU定义为：

$$ \exp\left(\min\left(0, 1 - \frac{\mathrm{len}_{\text{label}}}{\mathrm{len}_{\text{pred}}}\right)\right) \prod_{n=1}^k p_n^{1/2^n},$$

其中$\mathrm{len}_{\text{label}}$表示标签序列中的词元数和$\mathrm{len}_{\text{pred}}$表示预测序列中的词元数，$k$是用于匹配的最长的$n$元语法。另外，用$p_n$表示$n$元语法的精确度，它是两个数量的比值：第一个是预测序列与标签序列中匹配的$n$元语法的数量，
第二个是预测序列中$n$元语法的数量的比率。具体地说，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$
和预测序列$A$、$B$、$B$、$C$、$D$，我们有$p_1 = 4/5$、$p_2 = 3/4$、$p_3 = 1/3$和$p_4 = 0$。

根据BLEU的定义，当预测序列与标签序列完全相同时，BLEU为$1$。此外，由于$n$元语法越长则匹配难度越大，
所以BLEU为更长的$n$元语法的精确度分配更大的权重。具体来说，当$p_n$固定时，$p_n^{1/2^n}$会随着$n$的增长而增加（原始论文使用$p_n^{1/n}$）。而且，由于预测的序列越短获得的$p_n$值越高，所以BLEU中乘法项之前的系数用于惩罚较短的预测序列。例如，当$k=2$时，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$和预测序列$A$、$B$，尽管$p_1 = p_2 = 1$，惩罚因子$\exp(1-6/2) \approx 0.14$会降低BLEU。

• 根据“编码器-解码器”架构的设计，我们可以使⽤两个循环神经⽹络来设计⼀个序列到序列学习的模
型。
• 在实现编码器和解码器时，我们可以使⽤多层循环神经⽹络。
• 我们可以使⽤遮蔽来过滤不相关的计算，例如在计算损失时。
• 在“编码器－解码器”训练中，强制教学⽅法将原始输出序列（⽽⾮预测结果）输⼊解码器。
• BLEU是⼀种常⽤的评估⽅法，它通过测量预测序列和标签序列之间的n元语法的匹配度来评估预测。  

